\chapter{Matrix Product States} \label{chap:MPS}
Numerical analysis of quantum many-body systems using exact diagonalization is highly limited by system size. Due to the large number of possible configurations in a many-body system and entanglement coupling various degrees of freedom, the Hilbert space grows too large for exact methods to search.
Consider the Bose-Hubbard model described in eq. \eqref{BHhamil}. The dimension of the corresponding Hilbert space is
\begin{equation}
	D_{\mathcal{H}} = \frac{(L+N_p -1)!}{N_p ! (L-1)!} \; ,
	\label{eq:HilberSpaceScaling}
\end{equation}
where $L$ is the number of sites, and $N_p$ is the number of particles. For unit occupancy, $N_p / L = 1$, the Hilbert space grows exponentially with the system size \cite{Dong}. Therefore, descriptions using exact diagonalization are only possible for small systems.
Matrix product states parameterize the quantum states through a product of tensors, which can be depicted as a network. Decomposing the state as an explicitly contracted network of tensors enables efficient application of operators. Furthermore, the construction of matrix product states puts an upper bound on the entanglement entropy within the system, whereby states can be represented efficiently without considering unnecessary degrees of freedom \cite{Cramer}.

This chapter will cover the basics of matrix product states including their construction and freedom of gauges called canonical forms \cite{schollwock}. Furthermore, the generalization of MPS to operators called matrix product operators are introduced along with their applications. Algorithms involving matrix products states such as the DMRG method \cite{White1992,White1993} are introduced in the following chapter.


\section{Entanglement in Quantum Systems and Area Laws}
Entanglement is a fundamental property of quantum mechanics responsible for correlating different degrees of freedom within a quantum system. Thus, the individual parts of a quantum system can not be described alone, as entanglement with the remainder of the system has to be taken into consideration. This drastically complicates any description of the system, which is why exact descriptions of many-body systems are almost impossible.\\
The measure of entanglement within a quantum many-body system is the entanglement entropy, although it is often more instructive to look at the bipartite entanglement entropy, which measures the entanglement between two partitions of the system.
Consider a bipartition of the Hilbert space $\mathcal{H} = \mathcal{H}_A \otimes \mathcal{H}_B$. A state $\ket{\psi} \in \mathcal{H}$ can be decomposed using the \textit{Schmidt decomposition} as
\begin{equation}
	\ket{\psi} = \sum_{\alpha} \Lambda_{\alpha} \ket{\alpha}_A \otimes \ket{\alpha}_B \; ,
\end{equation}
where the states $\{ \ket{\alpha}_{A(B)} \}$ form an orthonormal basis of $\mathcal{H}_{A(B)}$, and $\Lambda_{\alpha} \ge 0$ are the Schmidt coefficients fulfilling $\sum_{\alpha} \Lambda_{\alpha}^2 = 1$ \cite{Pathak2013}. If only one term contributes to the Schmidt decomposition, the state is a product state i.e. the two parts of the Hilbert space are not mutually entangled. More terms implies that the state is entangled. From the Schmidt decomposition one can determine the reduced density matrix of the subsystem $A$
\begin{equation}
	\rho_A = \Tr _B \ket{\psi}\bra{\psi} = \sum_{\alpha} \Lambda_{\alpha}^2 \ket{\alpha}_A \bra{\alpha}_A \; ,  
\end{equation}
by tracing out the subsystem $B$. 
From the Schmidt decomposition one can determine the entanglement entropy of the bipartition, which is defined as the von-Neumann entropy, $S$, of the reduced density matrix given by \cite{Pathak2013}
\begin{equation}
	S = - \sum_{\alpha} \Lambda_{\alpha}^2 \log \Lambda_{\alpha}^2 \; .
	\label{eq:vNEntropy}
\end{equation}
Quite often, one is not concerned with the actual entanglement entropy of the system, but rather how it scales when the region in question grows in size. It is natural to assume that the entanglement entropy scales with  the \textit{volume} of the system, since this is the case for thermal systems. However, ground states of one-dimensional quantum many-body systems often follow an \textit{area law}, meaning that the scaling of the entropy is linear in the boundary area of the region. This is especially the case for systems with a gapped and local Hamiltonian \cite{Cramer}.\\
\begin{figure}[h!]
	\centering
	\input{Diagrams/LatticeCut.tex}
	\caption{Illustration of a cut in a one-dimensional lattice marked by the red, dashed line. The system follows an area law, whereby the entropy between the two bi-partitions of the system grows weaker at longer distances, which is depicted by the grey lines. }
	\label{fig:LatticeCut}
\end{figure}

In a one dimensional system, the size of an interface between two bipartitions is constant. Therefore, when bi-partitioning a one-dimensional system, the area of the boundary will be independent of where the cut is made. This effectively causes the entanglement entropy to be bounded above if the system follows an area law, as only degrees of freedom within the correlation length, $\xi$, of the boundary will be entangled \cite{Hastings2007}. Figure \ref{fig:LatticeCut} illustrates such a bi-partition. There, local states separated by more than $\xi$ from the boundary will not be entangled with states in the other bi-partition. Thus, the number of entangled degrees of freedom within the system is limited.

Area laws are the key to the success of numerical computations for one-dimensional systems, as the limited degree of entanglement enables the truncation of unused eigenstates without loss of accuracy in the representation of the state. Thus, one-dimensional quantum states can be efficiently described by tensor networks despite existing in an exponentially large Hilbert space.


\section{Construction of an MPS} \label{sec:construct_MPS}
Matrix products states are parameterizations of one dimensional quantum states through network of tensors.
This type of parameterization is especially intuitive for lattice systems, as each lattice site can be represented by a single tensor.
Consider the $n$'th single lattice site with the corresponding tensor $M_{\alpha_{n-1},\alpha_{n}}^{j_n}$. The state tensors have two different kinds of indices: First, the \textit{physical index}, $j_n$, corresponds to the local, physical states at the given site. Thus, when parameterizing the Bose-Hubbard model, the dimension of the physical index will be given by the dimension of the local Fock-space. Next, the \textit{bond indices}, $\alpha$, are virtual indices introduced during the construction of the tensor network. The bond indices serve to connect neighbouring sites, whereby their dimension is determined by the von-Neumann entropy associated with partitioning the system at said bond.

Tensors can be merged by contracting the bond connecting them, which is done by summing over their common index in the same way one would multiply two matrices.
Equations involving matrix product states tend to grow quite long due to the many indices. Therefore, tensor networks and their contractions are often depicted through diagrams. In the diagrammatic representation, the physical indices are marked by vertical legs, while bond indices are marked by horisontal legs. When the legs of two tensor are connected, it means that the corresponding bond is contracted. Further details and examples regarding tensor diagrams can be found in Appendix \ref{chap:diagrams}.\\

Consider a chain of $L$ sites with each site having a $d$-dimensional local Hilbert space $\{ \ket{j_n} \}$, where $n = 1, \ldots, L$. An arbitrary quantum state of this system reads
\begin{equation}
	\ket{\psi} = \sum_{j_1, \ldots, j_L}^{d} c_{j_1 \ldots j_L} \ket{j_1, \ldots, j_L} \; .
	\label{eq:arbstate}
\end{equation}
This description of a general state can be parametrized to the MPS form by applying successive Schmidt decomposition. However, in practice this is done through Singular Value Decompositions (SVD), as these are faster to perform numerically. The two approaches are equivalent, as the singular value decomposition is essentially a restatement of the Schmidt decomposition \cite{Pathak2013}.
Through an SVD, an arbitrary matrix, $A$, of dimensions $(M \times N)$ can be decomposed into three matrices, $A = U S V^{\dag}$, with the following properties \cite{schollwock}:
\begin{itemize}
\item
$U$ is of dimension $(M \times \min(M,N))$ and has orthonormal columns, meaning $U^{\dag}U = I$. If $M \leq N$, then it is also unitary $U U^{\dag} = I$.

\item
$S$ is a positive, diagonal $(\min(M,N) \times \min(M,N))$ matrix. The diagonal elements are singular values, and the number of non-zero entries is the Schmidt rank of $A$.

\item
$V^{\dag}$ is of dimension $(\min(M,N) \times N)$ and has orthonormal rows, meaning $V^{\dag}V = I$. If $M \geq N$, then it is also unitary $V V^{\dag} = I$.
\end{itemize} 
From the general state of eq. \eqref{eq:arbstate} an MPS can be constructed through the following steps:
\begin{enumerate}
\item
The $d^L$-dimensional vector $c_{j_1 \ldots j_L}$ is reshaped into a $(d \times d^{L-1})$ matrix $\Psi_{j_1 , (j_2 \ldots j_L)}$. Performing an SVD on $\Psi$ yields
\begin{equation}
	c_{j_1 \ldots j_L} = \Psi_{j_1 , (j_2 \ldots j_L)} = \sum_{\alpha_1}^{d} U_{j_1 , \alpha_1} S_{\alpha_1 , \alpha_1} (V^{\dag})_{\alpha_1 , (j_2 \ldots j_L)} = \sum_{\alpha_1}^{d} A_{\alpha_1}^{j_1} \Psi_{(\alpha_1 j_2),(j_3 \ldots j_L)} \; ,
\end{equation}
where $U$ has been reshaped into $d$ row vectors $A^{j_1}$ with entries $A_{\alpha_1}^{j_1} = U_{j_1 , \alpha_1}$. In this notation $A_{\alpha_1}^{j_1}$ is a tensor with the physical index $j_1$ and bond index $\alpha_1$. Furthermore, $S$ and $V^{\dag}$ has been multiplied and reshaped into a $(d^2 \times d^{L-2})$ matrix, $\Psi_{(\alpha_1 j_2),(j_3 \ldots j_L)}$.

\item
The new matrix $\Psi_{(\alpha_1 j_2),(j_3 \ldots j_L)}$ is subjected to an SVD decomposition
\begin{equation}
	c_{j_1 \ldots j_L} = \sum_{\alpha_1}^{d} \sum_{\alpha_2}^{d^2} A_{\alpha_1}^{j_1} U_{(\alpha_1 j_2) , \alpha_2} S_{\alpha_2 , \alpha_2} (V^{\dag})_{\alpha_2 , (j_3 \ldots j_L)} = \sum_{\alpha_1}^{d} \sum_{\alpha_2}^{d^2} A_{\alpha_1}^{j_1} A_{\alpha_1 , \alpha_2}^{j_2} \Psi_{(\alpha_2 j_3),(j_4 \ldots j_L)} \; ,
\end{equation}
where $U$ has been decomposed into $d$ matrices $A^{j_2}$ with entries $A_{\alpha_1 , \alpha_2}^{j_2} = U_{(\alpha_1 j_2) , \alpha_2}$. The matrix $\Psi_{(\alpha_2 j_3),(j_4 \ldots j_L)}$ has dimensions $(d^3 \times d^{L-3})$ and is yet again a product of the matrices $S$ and $V^{\dag}$ from the SVD.

\item
The procedure detailed in the two previous steps is continued throughout the chain leaving 
\begin{equation}
	c_{j_1 \ldots j_L} = \sum_{\alpha_1 , \ldots , \alpha_{L-1}} A_{\alpha_1}^{j_1} A_{\alpha_1 , \alpha_2}^{j_2} \ldots A_{\alpha_{L-2} ,\alpha_{L-1}}^{j_{L-1}} A_{\alpha_{L-1} ,\alpha_{L}}^{j_{L}} \equiv A^{j_1} A^{j_2} \ldots A^{j_{L-1}} A^{j_{L}} \; ,
\end{equation}
where the sum can be recognized as a matrix multiplication allowing a neater notation.
\end{enumerate}
\begin{figure}[h!]
	\centering
	\input{Diagrams/MPSbuild.tex}
	\caption{\textit{Diagrammatic representation of the construction of a left-canonical MPS from an arbitrary quantum state through successive SVD's.}}
	\label{fig:MPSbuild}
\end{figure}
The construction of an MPS is illustrated in figure \ref{fig:MPSbuild}. Thereby, the original state (equation \ref{eq:arbstate}) can be written as a matrix product state in the form \cite{schollwock}
\begin{equation}
	\ket{\psi} = \sum_{j_1, \ldots, j_L}^{d} A^{j_1} A^{j_2} \ldots A^{j_{L-1}} A^{j_{L}} \ket{j_1, \ldots, j_L} \; .
	\label{eq:MPS_LC} 
\end{equation}
Following the construction sequence, the dimensions of the matrices $A^{j_n}$ follow a pyramid-like structure $(1 \times d ),(d \times d^2) , \ldots , (d^{L/2 -1} \times d^{L/2}) , (d^{L/2} \times d^{L/2 -1 }), \ldots , (d \times 1)$, where $L$ is taken as even for simplicity. 
However, the state can be represented much more efficiently by truncating the dimensions of the bond indices, due to the area law scaling of entanglement entropy \cite{EntropyScaling}. A bond dimension $\chi$ infers an entanglement entropy bounded by $S(\rho_A) = \mathcal{O}(\log \chi)$ \cite{Gillman2018}, whereby one often can discard the contribution of many eigenstates without loss of accuracy. In practice this is done by keeping only the $D$ largest singular values of the SVD matrix $S$, as these contribute the most to the state. Alternatively  one can discard all eigenstates contributing with eigenvalues less than some threshold $\epsilon_t$.


\section{Canonical Forms}
\label{sec:canonical}
The MPS described in equation \ref{eq:MPS_LC} is not unique, as writing 
\begin{equation}
	\tilde{A}^{j_n} = X_{n-1} A^{j_n} X_{n}^{-1}
\end{equation}
describes the same state using different matrices. This gauge freedom allows expressing the MPS in whichever way is most convenient, which can greatly reduce the effort of applying operators and calculating overlaps. By choosing a gauge, the MPS is brought into a \textit{canonical form} \cite{Vidal2007}. The following examples detail bringing MPSs into canonical forms through construction, however, the same can be achieved for an already built MPS through successive SVDs and regrouping of the resulting matrices. 

\subsection{Left-canonical matrix product state}
The process of constructing an matrix product state detailed in Section \ref{sec:construct_MPS} brings the MPS in a \textit{left-canonical} form. This implies that all the matrices are left-normalized, such that
\begin{equation}
	\sum_{j_n} A^{j_n \dag} A^{j_n} = I \; .
	\label{eq:LC_ident}
\end{equation}
The left-normalization is a consequence of the matrix $U$ (from the SVD) fulfilling $U^{\dag}U = I$. Since the matrices $A^{j_n}$ are reshaped from $U$, these properties persists
\begin{align*}
	\delta_{\alpha_n , \alpha_n'} &= \sum_{\alpha_{n-1} j_n} (U^{\dag})_{\alpha_n , (\alpha_{n-1} j_n)} U_{(\alpha_{n-1} j_n), \alpha_n'} \\
	 &= \sum_{\alpha_{n-1} j_n} (A^{j_n \dag})_{\alpha_n , \alpha_{n-1}} A_{\alpha_{n-1}, \alpha_n'}^{j_n} \\
	 &= \sum_{j_n} \left( A^{j_n \dag} A^{j_n} \right)_{\alpha_{n} . \alpha_n'}
\end{align*} 
\begin{figure}[h!]
	\centering
	\input{Diagrams/leftNormalized.tex}
	\caption{\textit{Contraction over the left index (shown as the arc) and the physical index of two left-normalised matrices. The result is $\delta_{\alpha_n , \alpha_n'}$, adding the n'th site to the contraction of all previous sites to the left.}}
	\label{fig:leftNorm}
\end{figure}
Figure \ref{fig:leftNorm} illustrates a contraction of the bonds connecting two left-normalised matrices. As this contraction results in the identity per definition, one can contract left-normalised matrices without any explicit calculation. The explicit contraction is displayed diagrammatically through an arc, which is equivalent to an identity-tensor with two bond indices. 


\subsection{Right-canonical matrix product state}
One could also have built a a right-canonical MPS from eq. \eqref{eq:arbstate}, had one performed the SVDs from other side of the chain. Constructing the MPS from the right implies multiplying $U$ and $S$ into the new $\Psi$-matrix, and reshaping $(V^{\dag})_{(\alpha_{n-1} j_n), \alpha_n}$ into matrices $B_{\alpha_{n-1} , \alpha_n}^{j_n}$. Hence, the right-canonical form of the MPS of eq. \eqref{eq:MPS_LC} reads
\begin{equation}
	\ket{\psi} = \sum_{j_1, \ldots, j_L} B^{j_1} B^{j_2} \ldots B^{j_{L-1}} B^{j_{L}} \ket{j_1, \ldots, j_L} \; .
\label{eq:MPS_RC}	 
\end{equation}
In this form all the matrices are right-normalized, whereby 
\begin{equation}
	\sum_{j_n} B^{j_n} B^{j_n \dag} = I \; .
	\label{eq:RC_ident}
\end{equation}
Note the reverse ordering of the matrix product compared to the left-normalized case. Figure \ref{fig:rightNorm} illustrates two right-normalised matrices contracted over their physical index.
\begin{figure}[h!]
	\centering
	\input{Diagrams/rightNormalized.tex}
	\caption{\textit{Contraction over the right index (shown as the arc) and the physical index of two right-normalised matrices.}}
	\label{fig:rightNorm}
\end{figure}


\subsection{Mixed-canonical matrix product state}
In practice one rarely finds use for a purely left- or right-canonical MPS. However, combining the two canonical forms listed above yields the mixed-canonical form. The mixed-canonical results in a natural bi-partitioning of the system into a Schmidt decomposition, and it is especially useful for measuring local properties of the state \cite{schollwock}.\\
Consider the procedure of building an MPS in the left-canonical form, where $c_{j_1 \ldots j_L}$ has been decomposed from the left up until site $n$
\begin{equation}
	c_{j_1 \ldots j_L} = \sum_{\alpha_n} \left( A^{j_1} \ldots  A^{j_n} \right) _{\alpha_n} S_{\alpha_n , \alpha_n} (V^{\dag})_{\alpha_n , (j_{n+1} \ldots j_L)} \; .
\end{equation}
By reshaping $V^{\dag}$  into the matrix $\Psi_{(\alpha_n j_{n+1} \ldots j_{L-1}),j_L}$, one can initiate a successive decomposition from the right, resulting in a set of right-normalized matrices. The final result reads
\begin{equation}
	c_{j_1 \ldots j_L} = A^{j_1} \ldots A^{j_n} S B^{j_{n+1}} \ldots B^{j_L} \; ,
	\label{eq:mixedCanon}
\end{equation}
which is illustrated in figure \ref{fig:MixedCanonical1}.
\begin{figure}[h!]
\centering % <-- add this
\begin{subfigure}[b]{0.47\textwidth}
	\caption{}  	
  	\input{Diagrams/mixedCanonS.tex}
	\label{fig:MixedCanonical1}
\end{subfigure}
\hspace{5mm}
\begin{subfigure}[b]{0.47\textwidth}    
	\caption{}  	
  	\input{Diagrams/mixedCanon.tex}
	\label{fig:MixedCanonical2}
\end{subfigure}
\caption{Two variants of the mixed-canonical form of an MPS. The form \textbf{(a)} retains the matrix S originating from the SVD, whereby the MPS is directly brought into the form of a Schmidt decomposition. Multiplying S into either ites left or right neighbour creates the form \textbf{(b)}, which has a central site containing the normalization of the entire state. The form \textbf{(b)} is well suited for measuring local properties of the state.}
\end{figure}
In the mixed-canonical form the Schmidt decomposition can be read directly from the form of the MPS by introducing the vectors
\begin{align}
 	\ket{\alpha_n}_A \; &= \; \sum_{j_1 , \ldots , j_n} \left( A^{j_1} \ldots A^{j_n} \right)_{1,\alpha_n} \ket{j_1 , \ldots , j_n}  \label{eq:mixedA} \\
 	\ket{\alpha_n}_B \; &= \; \sum_{j_{n+1} , \ldots , j_L} \left( B^{j_{n+1}} \ldots B^{j_L} \right)_{\alpha_n , 1} \ket{j_{n+1} , \ldots , j_L} \; , \label{eq:mixedB}
\end{align}
whereby the state can be written in the form
\begin{equation}
	\ket{\psi} = \sum_{\alpha_n} S_{\alpha_n , \alpha_n} \ket{\alpha_n}_A \ket{\alpha_n}_B \; . \label{eq:MixedFormA}
\end{equation}
In order for eq. \eqref{eq:MixedFormA} to be considered a Schmidt decomposition, the matrix $S$ must fulfill $\sum_{\alpha_n} (S_{\alpha_n , \alpha_n})^2 = 1$, which is fulfilled by default by the SVD. Furthermore, the states $\ket{\alpha_n}_A$ and $\ket{\alpha_n}_B$ have to be orthonormal respectively, which they are by construction.\\
Another useful version of the mixed-canonical form is depicted in figure \ref{fig:MixedCanonical2}, where the matrix $S$ of eq. \eqref{eq:mixedCanon} has been multiplied unto the matrix to either the left or right of it. The result is a central cite, which is neither left- nor right-normalized, but instead contains the normalization of the entire state. Overlaps and expectation values can be computed very efficiently using the mixed-canonical form, as most of the tensor network can be explicitly contracted due to the normalization. 
 

\section{Matrix Product Operators} \label{sec:MPO}
A Matrix Product Operator (MPO) is an operator expressed in the formalism of an MPS. Thereby, operators can be incorporated as part of the tensor networks, where they are evaluated by the contraction of bonds.\\
Consider a single coefficient of an MPS of the state general $\ket{\psi}$
\begin{equation}
	\braket{j_1 , \ldots , j_L | \psi} = \braket{\boldsymbol{j} | \psi} = M^{j_1} M^{j_2} \ldots M^{j_L} \; . 
\end{equation}
Expressing an operator $\hat{O}$ in the basis of the local states, one can write it in a similar manner
\begin{equation}
	\hat{O} = \sum_{\boldsymbol{j} , \boldsymbol{j'}} \ket{\boldsymbol{j}} \bra{\boldsymbol{j}} \hat{O} \ket{\boldsymbol{j'}} \bra{\boldsymbol{j'}} = \sum_{\boldsymbol{j} , \boldsymbol{j'}} W^{j_1 , j_1 '} W^{j_2 , j_2 '} \ldots W^{j_L , j_L '} \ket{\boldsymbol{j}} \bra{\boldsymbol{j '}} \; ,
	\label{eq:MPOrep}
\end{equation}
where the coefficients are $\bra{\boldsymbol{j}} \hat{O} \ket{\boldsymbol{j'}} = W^{j_1 , j_1 '} W^{j_2 , j_2 '} \ldots W^{j_L , j_L '}$. The operator matrices, $W^{j_n , j_n '}$, differ from the state matrices, $M^{j_n}$, as the representation of the operators needs both an ingoing and an outgoing physical index. The ingoing physical index is depicted graphically as an extra vertical leg. A pictorial representation of the operator $\hat{O}$ can be seen in figure \ref{fig:MPOchain}.
\begin{figure}[h!]
	\centering
	\input{Diagrams/MPOchain.tex}
	\caption{An operator $\hat{O}$ expressed in the MPS form (MPO). The resulting matrix product operator has two physical indices marked by vertical lines, which corresponds to an ingoing and outgoing physical state.}
	\label{fig:MPOchain}
\end{figure}

\subsection{Applying an MPO to an MPS}
Applying a matrix product operator to a matrix product state is simply a matrix multiplication, where the matching physical indices are summed over:
\begin{align}
	\hat{O} \ket{\psi} &=  \sum_{\boldsymbol{j},\boldsymbol{j'}} \sum_{\boldsymbol{\alpha},\boldsymbol{\beta}} \left( M_{1, \alpha_1}^{ j_1 '} M_{\alpha_1, \alpha_2}^{j_2 '} \ldots \right) \left( W_{1, \beta_1}^{j_1 ' , j_1 } W_{\beta_1, \beta_2}^{j_2 ', j_2 } \ldots \right) \ket{\boldsymbol{j}} \nonumber \\
&= \sum_{\boldsymbol{j},\boldsymbol{j'}} \sum_{\boldsymbol{\alpha},\boldsymbol{\beta}} \left( M_{1, \alpha_1}^{ j_1 '} W_{1, \beta_1}^{j_1 ' , j_1} \right) \left( M_{\alpha_1, \alpha_2}^{j_2 '}  W_{\beta_1, \beta_2}^{j_2 ' , j_2} \right) \ldots \ket{\boldsymbol{j}} \nonumber \\
&= \sum_{\boldsymbol{j}} \sum_{\boldsymbol{\alpha},\boldsymbol{\beta}} N_{(1,1),(\alpha_1 , \beta_1)}^{j_1} N_{(\alpha_1 , \beta_1),(\alpha_2 , \beta_2)}^{j_2} \ldots \ket{\boldsymbol{j}} \nonumber \\
&\equiv \sum_{\boldsymbol{j}} N^{j_1} N^{j_2} \ldots \ket{\boldsymbol{j}} \; = \; \ket{\phi}
\label{eq:optBracketsMPO}
\end{align} 
The result is a new MPS, $\ket{\phi}$, which is described by the matrices $N^{j_n}$ and is illustrated in figure \ref{fig:MPOcont}. The bond dimensions of the new state matrices, $N$, are the product of the bond dimensions of the original MPS and MPO. Thus, applying an operator leaves the form of the MPS invariant but increases the matrix dimensions.
\begin{figure}[h!]
	\centering
	\input{Diagrams/MPOcontract.tex}
	\caption{\textit{Application of an MPO, $\hat{O}$, to an MPS, $\ket{\psi}$. Matching physical indices are contracted resulting in a new MPS, $\ket{\phi}$, with increased matrix dimensions.}}
	\label{fig:MPOcont}
\end{figure}
If the maximum bond dimension of the MPS is $D$, and the dimension of the MPO is $D_W$, the total computational cost of the operation is $\mathcal{O}(L d^2 D_W ^2 D^2)$ \cite{schollwock, McCulloch2007}.

\section{Correlation Functions and Measurement of Local Properties}
\label{sec:correlationFunctions}
Measuring local properties of a state is achieved by calculating the expectation value of local operators. Consider the local operator $\hat{O}^{[n]}$, where the square brackets denote the site, on which $\hat{O}$ operates. As $\hat{O}^{[n]}$ acts only on site $n$, it can be expressed in the local basis of said site
\begin{equation}
	\hat{O}^{[n]} = \sum_{j_n , j_n '} O^{j_n , j_n '} \ket{j_n} \bra{j_n '} \; .
	\label{eq:localOperator}
\end{equation}
Applying a local operator to a state implies applying the identity operator to all other sites. The full operator, $\hat{O} = \hat{I}^{[1]} \otimes \hat{I}^{[2]} \otimes \ldots \otimes \hat{O}^{[n]} \otimes \ldots \otimes \hat{I}^{[L]}$, can be expressed as an MPO and readily be applied to a matrix product state. However, the calculation is greatly simplified when considering an MPS in a mixed-canonical form, where the central tensor is located on site $n$. In that case, all the left-normalized matrices to the left of $n$ will contract to Kronecker deltas. The same happens for the right-normalized matrices to the right of $n$. Thereby, the entire tensor network on either side of site $n$ can be contracted  without any explicit calculations. The remaining network needed to be contracted is shown in figure \ref{fig:SingleSiteOperator}, which is simply the sum
\begin{equation}
	\bra{\psi} \hat{O}^{[n]} \ket{\psi} = \sum_{j_n , j_n '} O^{j_n , j_n '} \Tr \left( M^{j_n \dag} M^{j_n '} \right) 
\end{equation}
with the computational cost $\mathcal{O}(D^2 d^2)$ \cite{schollwock}.
\begin{figure}[h!]
\centering % <-- add this
\begin{subfigure}[b]{0.35\textwidth}
	\caption{}
  	\input{Diagrams/SingleSiteOperator.tex}
	\label{fig:SingleSiteOperator}
\end{subfigure}
\begin{subfigure}[b]{0.35\textwidth}
	\caption{}    
  	\input{Diagrams/DoubleSiteOperator.tex}
	\label{fig:DoubleSiteOperator}
\end{subfigure}
\caption{\textit{Measurement of local properties of a matrix product state in the mixed-canonical form.}}
\end{figure}
Very similar is the case of multiple-site local operator. However, sites on which the operator act can not be contracted explicitly. Thus, the resulting tensor network will look like the example shown in figure \ref{fig:DoubleSiteOperator}, where a two-site operator is measured.\\

Correlation functions can also be calculated efficiently using matrix product states in the mixed-canonical form. Consider the correlation $\bra{\psi} \hat{O}^{[n]} \hat{Q}^{[n+k]} \ket{\psi}$, whose corresponding tensor network is shown in figure \ref{fig:CorrelationFunction}.
\begin{figure}[h!]
	\centering
	\input{Diagrams/CorrelationFunctionNetwork.tex}
	\caption{\textit{Tensor network for the correlation function $\bra{\psi} \hat{O}^{[n]} \hat{Q}^{[n+4]} \ket{\psi}$. The outer parts of the network are implicitly contracted to identities following the mixed-canonical form of the MPS.}}
	\label{fig:CorrelationFunction}
\end{figure}
Bringing the MPS into a mixed-canonical form with the central tensor at site $m$ results in the outer parts of the network being explicitly contracted as identities. However, the otherwise right-normalized tensors between the two operators can not be contracted as identities, as the right-most operator breaks the canonical form. Thus, one has to contract a network of length $k+1$, which is done most efficiently following the optimal bracketing described in Appendix \ref{chap:diagrams}. The complexity of the entire contraction is of order $\mathcal{O}(k D^3 d)$. A consequence of parameterizing states through tensor networks is that correlation functions are represented as a linear combination of exponential functions. The derivation and discussion of this can be found in Appendix \ref{sec:CorrelationLength}.
